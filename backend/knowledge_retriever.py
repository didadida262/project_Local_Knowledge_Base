#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†æ£€ç´¢å™¨
é›†æˆOllamaå¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½é—®ç­”
"""

import requests
import json
import time
from typing import List, Dict, Any
from vector_knowledge_base import VectorKnowledgeBase


class KnowledgeRetriever:
    """çŸ¥è¯†æ£€ç´¢å™¨ç±»"""
    
    def __init__(self, knowledge_base: VectorKnowledgeBase, ollama_url: str = "http://localhost:11434", ollama_model: str = "gemma2:2b"):
        """
        åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢å™¨
        
        Args:
            knowledge_base: å‘é‡çŸ¥è¯†åº“å®ä¾‹
            ollama_url: OllamaæœåŠ¡åœ°å€
            ollama_model: Ollamaæ¨¡å‹åç§°
        """
        self.kb = knowledge_base
        self.ollama_url = ollama_url
        self.ollama_model = ollama_model
    
    def search(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        return self.kb.search(query, top_k)
    
    def ask_question(self, question: str, top_k: int = 5) -> Dict[str, Any]:
        """
        åŸºäºçŸ¥è¯†åº“è¿›è¡Œé—®ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢ç›¸å…³æ–‡æ¡£æ•°é‡
            
        Returns:
            é—®ç­”ç»“æœ
        """
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        search_results = self.search(question, top_k)
        
        if not search_results:
            return {
                'question': question,
                'answer': 'æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚',
                'sources': [],
                'confidence': 0.0
            }
        
        # 2. æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(search_results)
        
        # 3. è°ƒç”¨Ollamaç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(question, context)
        
        # 4. è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(search_results)
        
        return {
            'question': question,
            'answer': answer,
            'sources': search_results,
            'confidence': confidence
        }
    
    def _build_context(self, search_results: List[Dict[str, Any]]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        context_parts = []
        
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"æ–‡æ¡£ {i}: {result['file_name']}")
            context_parts.append(f"å†…å®¹: {result['text']}")
            context_parts.append(f"ç›¸ä¼¼åº¦: {result['similarity']:.3f}")
            context_parts.append("")
        
        return "\n".join(context_parts)
    
    def _generate_answer(self, question: str, context: str) -> str:
        """ä½¿ç”¨Ollamaç”Ÿæˆç­”æ¡ˆ"""
        prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š"""

        # æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ å°è¯•è°ƒç”¨Ollama (ç¬¬{attempt + 1}æ¬¡)...")
                response = requests.post(
                    f"{self.ollama_url}/api/generate",
                    json={
                        "model": self.ollama_model,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "top_p": 0.9,
                            "max_tokens": 1000
                        }
                    },
                    timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
                )
                
                if response.status_code == 200:
                    result = response.json()
                    print("âœ… Ollamaè°ƒç”¨æˆåŠŸ")
                    return result.get('response', 'æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆã€‚')
                else:
                    error_text = response.text
                    print(f"âš ï¸ Ollamaè¿”å›é”™è¯¯: {response.status_code}")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å‹ä¸å­˜åœ¨çš„é”™è¯¯
                    if "model" in error_text.lower() and ("not found" in error_text.lower() or "does not exist" in error_text.lower()):
                        error_msg = f"""
âŒ é”™è¯¯: Ollamaæ¨¡å‹ '{self.ollama_model}' æœªæ‰¾åˆ°æˆ–æœªä¸‹è½½

è§£å†³æ–¹æ¡ˆ:
1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å®‰è£…: ollama list
2. å¦‚æœæœªå®‰è£…ï¼Œè¿è¡Œ: ollama pull {self.ollama_model}
3. å®‰è£…å®Œæˆåé‡æ–°å¯åŠ¨æœåŠ¡

å½“å‰è¯·æ±‚çš„æ¨¡å‹: {self.ollama_model}
"""
                        print(error_msg)
                        return f"é”™è¯¯: æ¨¡å‹ {self.ollama_model} æœªå®‰è£…ï¼Œè¯·è¿è¡Œ 'ollama pull {self.ollama_model}' å®‰è£…æ¨¡å‹"
                    
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ ç­‰å¾…2ç§’åé‡è¯•...")
                        time.sleep(2)
                        continue
                    return f"OllamaæœåŠ¡é”™è¯¯: {response.status_code} - {error_text}"
                    
            except requests.exceptions.ConnectionError as e:
                print(f"âŒ è¿æ¥é”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    print(f"ğŸ”„ ç­‰å¾…3ç§’åé‡è¯•...")
                    time.sleep(3)
                    continue
                error_msg = """
âŒ é”™è¯¯: æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡

è§£å†³æ–¹æ¡ˆ:
1. æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ: ollama list
2. å¦‚æœæœªè¿è¡Œï¼Œå¯åŠ¨Ollama: ollama serve
3. ç¡®ä¿OllamaæœåŠ¡åœ°å€æ­£ç¡®: http://localhost:11434
4. å¦‚æœæœªå®‰è£…Ollamaï¼Œè®¿é—® https://ollama.ai ä¸‹è½½å®‰è£…

æ³¨æ„: å³ä½¿æ²¡æœ‰Ollamaï¼Œæœç´¢åŠŸèƒ½ä»ç„¶å¯ä»¥æ­£å¸¸ä½¿ç”¨
"""
                print(error_msg)
                return "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œã€‚"
            except requests.exceptions.Timeout as e:
                print(f"â° è¶…æ—¶é”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    print(f"ğŸ”„ ç­‰å¾…2ç§’åé‡è¯•...")
                    time.sleep(2)
                    continue
                return "OllamaæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
                if attempt < max_retries - 1:
                    print(f"ğŸ”„ ç­‰å¾…2ç§’åé‡è¯•...")
                    time.sleep(2)
                    continue
                return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        
        return "å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€ã€‚"
    
    def _calculate_confidence(self, search_results: List[Dict[str, Any]]) -> float:
        """è®¡ç®—ç­”æ¡ˆç½®ä¿¡åº¦"""
        if not search_results:
            return 0.0
        
        # åŸºäºæœ€é«˜ç›¸ä¼¼åº¦è®¡ç®—ç½®ä¿¡åº¦
        max_similarity = max(result['similarity'] for result in search_results)
        
        # å°†ç›¸ä¼¼åº¦è½¬æ¢ä¸ºç½®ä¿¡åº¦ (0-1)
        confidence = min(max_similarity, 1.0)
        
        return confidence
    
    def get_ollama_models(self) -> List[str]:
        """è·å–å¯ç”¨çš„Ollamaæ¨¡å‹åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return [model['name'] for model in data.get('models', [])]
            else:
                return []
        except:
            return []
    
    def check_ollama_connection(self) -> bool:
        """æ£€æŸ¥Ollamaè¿æ¥çŠ¶æ€"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
