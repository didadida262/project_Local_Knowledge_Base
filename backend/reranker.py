#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ’æ¨¡å‹
ä½¿ç”¨BAAI/bge-reranker-largeå¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åº
"""

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Dict, Any
import numpy as np


class Reranker:
    """é‡æ’æ¨¡å‹ç±»"""
    
    def __init__(self, model_name: str = "BAAI/bge-reranker-large"):
        """
        åˆå§‹åŒ–é‡æ’æ¨¡å‹
        
        Args:
            model_name: é‡æ’æ¨¡å‹åç§°
        """
        self.model_name = model_name
        print(f"ğŸ”„ åŠ è½½é‡æ’æ¨¡å‹: {model_name}")
        
        # åŠ è½½tokenizerå’Œæ¨¡å‹
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… é‡æ’æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def rerank(self, query: str, documents: List[Dict[str, Any]], top_k: int = None) -> List[Dict[str, Any]]:
        """
        å¯¹æœç´¢ç»“æœè¿›è¡Œé‡æ–°æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            é‡æ–°æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not documents:
            return []
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        pairs = []
        for doc in documents:
            pairs.append([query, doc['text']])
        
        # æ‰¹é‡è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        scores = self._compute_scores(pairs)
        
        # æ·»åŠ é‡æ’åˆ†æ•°åˆ°æ–‡æ¡£
        for i, doc in enumerate(documents):
            doc['rerank_score'] = float(scores[i])
        
        # æŒ‰é‡æ’åˆ†æ•°æ’åº
        reranked_docs = sorted(documents, key=lambda x: x['rerank_score'], reverse=True)
        
        # è¿”å›top_kç»“æœ
        if top_k is not None:
            return reranked_docs[:top_k]
        
        return reranked_docs
    
    def _compute_scores(self, pairs: List[List[str]]) -> np.ndarray:
        """
        è®¡ç®—æŸ¥è¯¢-æ–‡æ¡£å¯¹çš„ç›¸å…³æ€§åˆ†æ•°
        
        Args:
            pairs: æŸ¥è¯¢-æ–‡æ¡£å¯¹åˆ—è¡¨
            
        Returns:
            ç›¸å…³æ€§åˆ†æ•°æ•°ç»„
        """
        # æ‰¹é‡ç¼–ç 
        inputs = self.tokenizer(
            pairs,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors='pt'
        )
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # è®¡ç®—åˆ†æ•°
        with torch.no_grad():
            outputs = self.model(**inputs)
            scores = torch.sigmoid(outputs.logits).squeeze().cpu().numpy()
        
        return scores
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_name': self.model_name,
            'device': str(self.device),
            'max_length': 512
        }
