# 本地向量知识库系统 PRD

## 1. 产品概述

### 1.1 产品名称
本地向量知识库系统 (Local Vector Knowledge Base System)

### 1.2 产品定位
基于本地Ollama大语言模型的智能文档检索与问答系统，支持多格式文档的向量化存储和语义搜索。

### 1.3 目标用户
- 个人用户：需要本地化文档管理和智能检索
- 企业用户：需要私有化部署的知识库系统
- 研究人员：需要基于文档的智能问答功能

## 2. 核心功能需求

### 2.1 文档管理功能
- **默认语料库**：系统启动时自动加载`docs/`目录下的所有文档
- **文档格式支持**：PDF、Word、Markdown、HTML、TXT等主流格式
- **用户上传**：支持用户自主上传其他文档到知识库
- **文档预览**：支持文档内容预览和元数据展示

### 2.2 向量化存储
- **文档解析**：自动解析各种格式的文档内容
- **文本分块**：将长文档分割为适合处理的文本块
- **向量化**：使用Sentence Transformers生成文档向量
- **索引存储**：使用FAISS进行高效的向量索引存储

### 2.3 智能检索功能
- **语义搜索**：基于向量相似度的语义搜索
- **关键词搜索**：支持传统的关键词匹配搜索
- **搜索结果排序**：按相关度排序显示搜索结果
- **搜索预览**：显示匹配的文档片段和相似度分数

### 2.4 AI问答功能
- **上下文理解**：基于检索到的相关文档进行问答
- **多轮对话**：支持连续的多轮问答交互
- **答案溯源**：显示答案来源的文档和位置
- **置信度评估**：提供答案的可信度评分

## 3. 技术架构

### 3.1 前端技术栈
- **框架**：React 18 + TypeScript
- **UI库**：Aceternity UI（暗黑主题）
- **动画**：Framer Motion
- **样式**：Tailwind CSS
- **构建工具**：Vite
- **HTTP客户端**：Axios

### 3.2 后端技术栈
- **语言**：Python 3.8+
- **Web框架**：Python内置http.server
- **向量化**：Sentence Transformers
- **向量存储**：FAISS
- **文档处理**：PyPDF2, python-docx, BeautifulSoup4
- **大语言模型**：Ollama (本地部署)

### 3.3 系统架构
```
用户界面 (React前端)
    ↓ HTTP API
API服务器 (Python)
    ↓
向量知识库 (FAISS + Sentence Transformers)
    ↓
Ollama大语言模型 (本地)
```

## 4. 用户界面设计

### 4.1 设计风格
- **主题**：暗黑系Aceternity UI风格
- **色彩**：深色背景配合渐变色彩
- **动效**：流畅的动画过渡和交互反馈
- **布局**：现代化卡片式布局

### 4.2 主要页面
- **首页**：知识库统计信息和快速入口
- **搜索页**：智能搜索界面和结果展示
- **问答页**：AI问答对话界面
- **文档管理页**：文档上传和管理功能

## 5. 功能详细设计

### 5.1 搜索功能
**输入**：用户输入搜索关键词或问题
**处理**：
1. 将查询文本向量化
2. 在FAISS索引中搜索相似向量
3. 返回按相似度排序的结果
**输出**：显示匹配的文档片段和来源信息

### 5.2 问答功能
**输入**：用户提问
**处理**：
1. 基于问题检索相关文档
2. 将检索结果作为上下文发送给Ollama
3. 生成基于文档的答案
**输出**：AI生成的答案和参考文档

### 5.3 文档管理
**上传流程**：
1. 用户选择或拖拽文件上传
2. 系统解析文档内容
3. 生成向量并存储到FAISS
4. 更新知识库索引

## 6. 性能要求

### 6.1 响应时间
- **搜索响应**：< 2秒
- **问答响应**：< 5秒
- **文档上传**：< 10秒（取决于文档大小）

### 6.2 并发支持
- **同时用户**：支持10+并发用户
- **文档容量**：支持10,000+文档存储
- **向量维度**：384维向量存储

## 7. 部署要求

### 7.1 系统要求
- **操作系统**：Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **内存**：8GB+ RAM
- **存储**：10GB+ 可用空间
- **网络**：本地网络访问

### 7.2 依赖要求
- **Python**：3.8+
- **Node.js**：16+
- **Ollama**：最新版本
- **模型**：qwen3:8b 或类似模型

## 8. 启动流程

### 8.1 一键启动
- **脚本文件**：`start.bat`（Windows）或`start.sh`（Linux/Mac）
- **启动流程**：
  1. 检查系统依赖
  2. 启动后端API服务器
  3. 启动前端开发服务器
  4. 自动打开浏览器

### 8.2 手动启动
- **后端**：`python backend/simple_api_server.py`
- **前端**：`cd frontend && npm run dev`

## 9. 安全要求

### 9.1 数据安全
- **本地存储**：所有数据存储在本地，不上传云端
- **访问控制**：仅本地网络访问
- **数据加密**：敏感数据本地加密存储

### 9.2 隐私保护
- **无数据收集**：不收集用户使用数据
- **无网络传输**：除模型下载外无网络传输
- **完全离线**：支持完全离线使用

## 10. 扩展性设计

### 10.1 模型支持
- **多模型**：支持切换不同的Ollama模型
- **模型管理**：支持模型的下载和切换
- **性能优化**：支持模型量化以降低资源占用

### 10.2 功能扩展
- **插件系统**：支持自定义插件扩展
- **API接口**：提供RESTful API供第三方集成
- **批量处理**：支持批量文档处理功能

## 11. 测试要求

### 11.1 功能测试
- **搜索准确性**：验证搜索结果的相关性
- **问答质量**：评估AI回答的准确性和完整性
- **文档处理**：测试各种格式文档的解析能力

### 11.2 性能测试
- **响应时间**：测试各功能的响应时间
- **并发测试**：测试多用户同时使用的性能
- **压力测试**：测试系统在高负载下的稳定性

## 12. 交付物

### 12.1 代码交付
- **前端代码**：React + TypeScript + Aceternity UI
- **后端代码**：Python API服务器
- **配置文件**：部署和配置文件
- **文档**：用户手册和开发文档

### 12.2 部署包
- **启动脚本**：一键启动脚本
- **依赖管理**：requirements.txt和package.json
- **部署指南**：详细的部署和配置说明

---

